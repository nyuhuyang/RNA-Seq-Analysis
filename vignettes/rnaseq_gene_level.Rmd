---
title: "rnaseq_gene_level.Rmd"
author: "Yang Hu"
date: "2017/5/5"
output: html_document
---
## Introduction

In this section, we will focus on comparing the expression levels of genes across different samples. This analysis sets aside the task of estimating the different kinds of RNA molecules, and the different isoforms for genes with multiple isoforms. One advantage of looking at these matrices of counts is that we can use statistical distributions to model how the variance of counts will change when the counts are low vs high. We will explore the relationship of the variance of counts to the mean later in this lab.

## Counting reads in genes

In this section we will examine 75 samples from Waldenstrom Macroglobulinemia patients, in a cohort called ???zhunter,??? from Harvard University. 

## Construct sample.table

```{r}
setwd("/Users/yah2014/Dropbox/Public/Olivier/R/zhunter/Mutation");getwd() #set_up_enviroment

sample_zhunter.table <- read.csv("sample_table_zhunter.csv")
fileName <-paste0(sample_zhunter.table$BioSample, ".bam.count")
sample_zhunter.table <- data.frame(sampleName = sample_zhunter.table$sampleName,
                                   fileName = fileName,
                                   Condition= sample_zhunter.table$Condition,
                                   QC = sample_zhunter.table$QC,
                                   Label= sample_zhunter.table$Label,
                                   BioSample = sample_zhunter.table$BioSample)
head(sample_zhunter.table)
```

## Creating a DESeqDataSet object

```{r results='hide', message=FALSE, warning=FALSE}
invisible(library(DESeq2))
```

```{r}
directory <- "/Users/yah2014/Dropbox/Public/Olivier/R/ALL_COUNTS/zhunter_Counts" #dir for HTSeq Counts
ddsHTSeq <- DESeqDataSetFromHTSeqCount(sampleTable = sample_zhunter.table,
                                       directory = directory,
                                       design= ~ Condition)
ddsHTSeq
```

if Error in `colnames<-`(`*tmp*`, value = 1:75) : 
attempt to set 'colnames' on an object with less than two dimensions
clean the first row with the empty first column and "0" in the second column in HTSeq.count files
use terminal, run below command lines to remove first line for all files:
cd /Users/yah2014/Dropbox/Public/Olivier/R/ALL_COUNTS/zhunter_Counts
for file in $(ls);do echo "$(tail -n +2 $file)" > $file;done

### Normalization for sequencing depth
####Pre-filtering

removing rows in which there are no reads or nearly no reads
```{r}
ddsHTSeq <- ddsHTSeq[ rowSums(counts(ddsHTSeq)) > 1, ]
```

Note on factor levels

```{r}
ddsHTSeq$Condition <- factor(ddsHTSeq$Condition, levels=c("Cancer","Healthy","Unclear"))
ddsHTSeq$Label <- factor(ddsHTSeq$Label, levels=c("NWM","rnaWT","WM","MWCL","BCWM"))
```

The following estimates size factors to account for differences in sequencing depth, and is only necessary to make the `log.norm.counts` object below.

```{r}
dds <- estimateSizeFactors(ddsHTSeq)
head(sizeFactors(dds))
head(colSums(counts(dds)))
plot(sizeFactors(dds), colSums(counts(dds)))
abline(lm(colSums(counts(dds)) ~ sizeFactors(dds) + 0))
```

Size factors are calculated by the median ratio of samples to a pseudo-sample (the geometric mean of all samples). In other words, for each sample, we take the exponent of the median of the log ratios in this histogram.

```{r}
loggeomeans <- rowMeans(log(counts(dds)))
hist(log(counts(dds)[,1]) - loggeomeans, 
     col="grey", main="", xlab="", breaks=40)
```

The size factor for the first sample:

```{r}
exp(median((log(counts(dds)[,1]) - loggeomeans)[is.finite(loggeomeans)]))
sizeFactors(dds)[1]
```

Make a matrix of log normalized counts (plus a pseudocount):

```{r}
log.norm.counts <- log2(counts(dds, normalized=TRUE) + 1)
```

Examine the log normalized counts (plus a pseudocount).

```{r}
rs <- rowSums(counts(dds))
boxplot(log.norm.counts[rs > 0,]) # normalized
```

Make a scatterplot of log normalized counts against each other. Note the fanning out of the points in the lower left corner, for points less than $2^5 = 32$.

```{r}
plot(log.norm.counts[,1:2], cex=.1)
```

### Stabilizing count variance

Now we will use a more sophisticated transformation, which is similar to the variance stablizing normalization method taught in Week 3 of Course 4: Introduction to Bioconductor. It uses the variance model for count data to shrink together the log-transformed counts for genes with very low counts. For genes with medium and high counts, the `rlog` is very close to `log2`. For further details, see the section in the DESeq2 [paper](#foot).  
This will take five minutes!!
```{r}
#rld <- rlog(dds)
#plot(assay(rld)[,1:2], cex=.1)
```

Another transformation for stabilizing variance in the *DESeq2* package is `varianceStabilizingTransformation`. These two tranformations are similar, the *rlog* might perform a bit better when the size factors vary widely, and the *varianceStabilizingTransformation* is much faster when there are many samples.

```{r}
vsd <- varianceStabilizingTransformation(dds)
plot(assay(vsd)[,1:2], cex=.1)
```

We can examine the standard deviation of rows over the mean for the *vsd*. Note that the genes with high variance for the *log* come from the genes with lowest mean. If these genes were included in a distance calculation, the high variance at the low count range might overwhelm the signal at the higher count range.

```{r}
library(vsn)
meanSdPlot(assay(vsd), ranks=FALSE)
```

The principal components (PCA) plot is a useful diagnostic for examining relationships between samples:

Using the VST:

```{r}
plotPCA(vsd, intgroup="Condition")
```

We can make this plot even nicer using custom code from the *ggplot2* library:

```{r}
library(ggplot2)
head((data <- plotPCA(vsd, intgroup=c("Condition","Label"), returnData=TRUE)))
(percentVar <- 100*round(attr(data, "percentVar"),2))
```

```{r}
makeLab <- function(x,pc) paste0("PC",pc,": ",x,"% variance")
ggplot(data, aes(PC1,PC2,col=Condition,shape=Label)) + geom_point() +
  xlab(makeLab(percentVar[1],1)) + ylab(makeLab(percentVar[2],2))
```

In addition, we can plot a hierarchical clustering based on Euclidean distance matrix:

```{r fig.width=10, fig.height=5}
plot(hclust(dist(t(log.norm.counts))), labels=colData(dds)$Condition,cex = 0.75)
```

```{r fig.width=10, fig.height=5}
plot(hclust(dist(t(assay(vsd)))), labels=colData(vsd)$Condition,cex = 0.75)
```

## Differential gene expression

### Modeling raw counts with normalization

We will now perform *differential gene expression* on the counts, to try to find genes in which the differences in expected counts across samples due to the condition of interest rises above the biological and technical variance we observe. 

We will use an overdispersed Poisson distribution -- called the negative binomial -- to model the *raw counts* in the count matrix. The model will include the *size factors* into account to adjust for sequencing depth. The formula will look like:

$$ K_{ij} \sim \text{NB}(s_{ij} q_{ij}, \alpha_i ) $$

where $K_{ij}$ is a single raw count in our count table, $s_{ij}$ is a size factor or more generally a normalization factor, $q_{ij}$ is proportional to gene expression (what we want to model with our design variables), and $\alpha_i$ is a *dispersion parameter*.

Why bother modeling *raw counts*, rather than dividing out the sequencing depth and working with the normalized counts? In other words, why put the $s_{ij}$ on the right side of the equation above, rather than dividing out on the left side and modeling $K_{ij} / s_{ij}$. The reason is that, with the raw count, we have knowledge about the link between the expected value and its variance. So we prefer the first equation below to the second equation, because with the first equation, we have some additional information about the variance of the quantity on the left hand side.

$$ K_{ij} \sim \text{NB}(\mu_{ij} = s_{ij} q_{ij} ) $$

$$ \frac{K_{ij}}{s_{ij}} \sim \mathcal{L}(\mu_{ij} = q_{ij}) $$

When we sample cDNA fragments from a pool in a sequencing library, we can model the count of cDNA fragments which originated from a given gene with a binomial distribution, with a certain probability of picking a fragment for that gene which relates to factors such as the expression of that gene (the abundance of mRNA in the original population of cells), its length and technical factors in the production of the library. When we have many genes, and the rate for each gene is low, while the total number of fragments is high, we know that the Poisson is a good model for the binomial. And for the binomial and the Poisson, there is an explicit link between on observed count and its expected variance.

A number of methods for assessing differential gene expression from RNA-seq counts use the negative binomial distribution to make probabilistic statements about the differences seen in an experiment. A few such methods are *edgeR*, *DESeq2*, and *DSS*. Other methods, such as *limma+voom* find other ways to explicitly model the mean of log counts and the observed variance of log counts. A very incomplete list of statistical methods for RNA-seq differential expression is provided in the [footnotes](#foot).

*DESeq2* performs a similar step to *limma* as discussed in PH525x Course 3, in using the variance of all the genes to improve the variance estimate for each individual gene. In addition, *DESeq2* shrinks the unreliable fold changes from genes with low counts, which will be seen in the resulting MA-plot.

### Experimental design and running DESeq2

Remember, we had created the *DESeqDataSet* object earlier using the following line of code (or alternatively using *DESeqDataSetFromMatrix*)

```{r}
dds <- DESeqDataSet(ddsHTSeq, design= ~ Condition)
```

First, we setup the `design` of the experiment, so that differences will be considered across time and protocol variables. We can read and if necessary reset the design using the following code.

```{r}
design(dds)
design(dds) <- ~Condition
```

The last variable in the design is used by default for building results tables (although arguments to `results` can be used to customize the results table), and we make sure the "control" or "untreated" level is the first level, such that log fold changes will be treated over control, and not control over treated.


```{r}
levels(dds$Condition)
dds$Condition <- relevel(dds$Condition, "Unclear")
dds$Condition <- relevel(dds$Condition, "Healthy")
levels(dds$Condition)
```

The following line runs the *DESeq2* model. After this step, we can build a results table, which by default will compare the levels in the last variable in the design, so the *Condition* treatment in our case:

```{r results='hide', message=FALSE, warning=FALSE}
dds <- DESeq(dds)
res <- results(dds)
```

### Examining results tables

```{r}
head(res)
table(res$padj < 0.1)
```

A summary of the results can be generated:

```{r}
summary(res)
```

For testing at a different threshold, we provide the `alpha` to *results*, so that the mean filtering is optimal for our new FDR threshold.

```{r}
res2 <- results(dds, alpha=0.05)
table(res2$padj < 0.05)
```
#Exporting results to CSV files

```{r}
resO5rdered <- res2[order(res2$padj),]
write.csv(as.data.frame(resO5rdered), 
          file="condition_treated_results.csv")
```

### Visualizing results

The MA-plot provides a global view of the differential genes, with the log2 fold change on the y-axis over the mean of normalized counts:

```{r}
plotMA(res, ylim=c(-8,4))
```

We can also test against a different null hypothesis. For example, to test for genes which have fold change more than doubling or less than halving:

```{r}
res.thr <- results(dds, lfcThreshold=1)
plotMA(res.thr, ylim=c(-8,4))
```


A p-value histogram:

```{r}
hist(res$pvalue[res$baseMean > 1], 
     col="grey", border="white", xlab="", ylab="", main="")
```

A sorted results table:

```{r}
resSort <- res[order(res$padj),]
head(resSort)
```

Examine the counts for the top gene, sorting by p-value:

```{r}
plotCounts(dds, gene=which.min(res$padj), intgroup="Condition")
```

Make normalized counts plots for the top 9 genes:

```{r}
par(mfrow=c(3,3))
for (i in 1:9)  plotCounts(dds, order(res$padj)[i], intgroup="Condition")
```

A more sophisticated plot of counts:

```{r}
library(ggplot2)
data <- plotCounts(dds, gene=which.min(res$padj), intgroup=c("Condition","Label"), returnData=TRUE)
ggplot(data, aes(x=Condition, y=count, col=Label)) +
  geom_point(position=position_jitter(width=.1,height=0)) +
  scale_y_log10()
```

Connecting by lines shows the differences which are actually being tested by *results* given that our design includes `cell + Condition`

```{r}
par(mfrow=c(1,1))
ggplot(data, aes(x=Condition, y=count, col=Label, group=Label)) +
  geom_point() + geom_line() + scale_y_log10() 
```




A heatmap of the top genes:

```{r}
library(pheatmap)
topgenes <- head(rownames(resSort),20)
mat <- assay(vsd)[topgenes,]
mat <- mat - rowMeans(mat)
df <- as.data.frame(colData(dds)[,c("Condition","Label")])
pheatmap(mat, annotation_col=df, fontsize_col=6)
```

### Getting alternate annotations

We can then check the annotation of these highly significant genes:

```{r}
#library(org.Hs.eg.db)
#keytypes(org.Hs.eg.db)
#anno <- select(org.Hs.eg.db, keys=topgenes,
#               columns=c("SYMBOL","GENENAME"), 
#               keytype="ENSEMBL")
#anno[match(topgenes, anno$ENSEMBL),]
#for Bioconductor >= 3.1, easier to use mapIds() function
```

### Looking up different results tables

The `contrast` argument allows users to specify what results table should be built. See the help and examples in `?results` for more details:

```{r}
#results(dds, contrast=c("cell","N61311","N052611"))
```

### Surrogate variable analysis for RNA-seq

If we suppose that we didn't know about the different cell-lines in the experiment, but noticed some structure in the counts, we could use surrograte variable analysis (SVA) to detect this hidden structure (see PH525x Course 3 for details on the algorithm).

```{r}
library(sva)
dat <- counts(dds, normalized=TRUE)
idx <- rowMeans(dat) > 1
dat <- dat[idx,]
mod <- model.matrix(~ Condition, colData(dds))
mod0 <- model.matrix(~ 1, colData(dds))
svseq <- svaseq(dat, mod, mod0, n.sv=2)
```

Do the surrogate variables capture the cell difference?

```{r}
par(mfrow=c(1,1))
plot(svseq$sv[,1], svseq$sv[,2], col=dds$Label,pch=16)
legend("topright",pch = 16, col=1:5,levels(dds$Label))
#text(svseq$sv[,1], svseq$sv[,2], 1:ncol(dds), pos=1)
```

Do the surrogate variables capture the health condition?

```{r}
plot(svseq$sv[,1], svseq$sv[,2], col=dds$Condition,pch=16)
legend("topright",pch = 16, col=1:3,levels(dds$Condition))
#text(svseq$sv[,1], svseq$sv[,2], 1:ncol(dds), pos=1)
```

Using the surrogate variables in a *DESeq2* analysis:

```{r}
#dds.sva <- dds
#dds.sva$SV1 <- svseq$sv[,1]
#dds.sva$SV2 <- svseq$sv[,2]
#design(dds.sva) <- ~ SV1 + SV2 + Condition
#dds.sva <- DESeq(dds.sva)
```

## Session info

```{r}
sessionInfo()
```
